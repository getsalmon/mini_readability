Будем исходить из предположения, что весь контент статьи обернут в один html-tag
Скорее всего такими тэгами будут: div, article, section, main

Так как мы ищем тексты статей, то нам нужно найти тэг, в котором содержится 
наибольшее количество предложений. 
Предложения будем вычленять регулярным выражением.

Алгоритм работы:
- загружаем страницу с помощью requests.get
- формируем по контенту страницы объект BeautifulSoup
- очищаем soup от ненужных тэгов (e.g. script, link, iframe, img)
- рекурсивно ищем в DOM узел с наибольшим количеством предложений
- найденный узел форматируем согласно правилам
- сохраняем файл

Описание файлов:
- main.py - основной исполняемый файл
- config.py - конфиг файл
- article_scraper.py - скрапер. работает с DOM, в том числе ищет узел с 
наибольшим количеством предложений
- filesystem_worker.py - класс FileSystemWorker для работы с ФС 
(создание папок, вычленение имени файла из URL)
- format_rules.py - правила форматирования тэгов
- misc.py - скачивание статьи
- txtmaker.py - класс TxtMaker служит для получения текстового файла из html 
по правилам форматирования